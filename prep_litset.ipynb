{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select csv files to read\n",
      "0: lit_WOK_2021-07-01_2024-05-31.csv\n",
      "1: lit_pubmed_2021-07-01_2024-05-31.csv\n",
      "2: lit_WOS_2021-07-01_2024-05-31.csv\n",
      "3: lit_acm_2021-07-01_2024-05-31.csv\n",
      "Data read successfully\n"
     ]
    }
   ],
   "source": [
    "# read in files in literature folder\n",
    "literature_files = os.listdir('literature')\n",
    "# keep only csv files and those that start with 'lit_'\n",
    "literature_files = [file for file in literature_files if file.endswith('.csv') and file.startswith('lit_')]\n",
    "\n",
    "# ask for user input to select csv files to read\n",
    "print('Select csv files to read')\n",
    "for i, file in enumerate(literature_files):\n",
    "    print(f'{i}: {file}')\n",
    "selected_files = input('Enter the number of the files separated by commas: ')\n",
    "selected_files = selected_files.split(',')\n",
    "selected_files = [int(i) for i in selected_files]\n",
    "\n",
    "# read in selected files, have a new column that indicates the source of the data\n",
    "data = []\n",
    "for i in selected_files:\n",
    "    file = literature_files[i]\n",
    "    df = pd.read_csv(f'literature/{file}')\n",
    "    # the source is the second part of the file name\n",
    "    source = file.split('_')[1].split('.')[0]\n",
    "    df['source'] = source\n",
    "    data.append(df)\n",
    "\n",
    "data = pd.concat(data)\n",
    "print('Data read successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for each source\n",
      "source\n",
      "acm       3651\n",
      "WOK       1262\n",
      "pubmed     336\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print number of rows for each source\n",
    "print('Number of rows for each source')\n",
    "print(data['source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5249, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication Type</th>\n",
       "      <th>SourceTitle</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>UT</th>\n",
       "      <th>DOI</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>source</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>PMID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unravelling the molecular dimensions of atmosp...</td>\n",
       "      <td>Nazeer, Nazim; Bhargava, Arpit; Soni, Nikita; ...</td>\n",
       "      <td>Article</td>\n",
       "      <td>PHYSICS AND CHEMISTRY OF THE EARTH</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Air pollution, Artificial intelligence, Enviro...</td>\n",
       "      <td>WOS</td>\n",
       "      <td>10.1016/j.pce.2024.103604</td>\n",
       "      <td>1474-7065</td>\n",
       "      <td>WOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simultaneous thermal zoning and demand control...</td>\n",
       "      <td>Rodriguez, Jose; Fumo, Nelson</td>\n",
       "      <td>Article</td>\n",
       "      <td>ENERGY REPORTS</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Thermal zoning, Demand control ventilation, Es...</td>\n",
       "      <td>WOS</td>\n",
       "      <td>10.1016/j.egyr.2024.04.025</td>\n",
       "      <td>2352-4847</td>\n",
       "      <td>WOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exploring the influence of indoor environment ...</td>\n",
       "      <td>Ma, Chuan; Guerra-Santin, Olivia; Mohammadi, Masi</td>\n",
       "      <td>Article</td>\n",
       "      <td>BUILDING AND ENVIRONMENT</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Nursing home, Indoor environment, Spatial layo...</td>\n",
       "      <td>WOS</td>\n",
       "      <td>10.1016/j.buildenv.2024.111452</td>\n",
       "      <td>0360-1323</td>\n",
       "      <td>WOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radon Exposure Assessment in Occupational and ...</td>\n",
       "      <td>Kholopo, Mota; Rathebe, Phoka Caiphus</td>\n",
       "      <td>Article</td>\n",
       "      <td>SENSORS</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>radon, environmental exposure, occupational se...</td>\n",
       "      <td>WOS</td>\n",
       "      <td>10.3390/s24102966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Semi-supervised ensemble learning for human ac...</td>\n",
       "      <td>Patricia, Ariza-Colpas Paola; Rosberg, Pacheco...</td>\n",
       "      <td>Article</td>\n",
       "      <td>HELIYON</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Human activity recognition, Activities of dail...</td>\n",
       "      <td>WOS</td>\n",
       "      <td>10.1016/j.heliyon.2024.e29398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Unravelling the molecular dimensions of atmosp...   \n",
       "1  Simultaneous thermal zoning and demand control...   \n",
       "2  Exploring the influence of indoor environment ...   \n",
       "3  Radon Exposure Assessment in Occupational and ...   \n",
       "4  Semi-supervised ensemble learning for human ac...   \n",
       "\n",
       "                                             Authors Publication Type  \\\n",
       "0  Nazeer, Nazim; Bhargava, Arpit; Soni, Nikita; ...          Article   \n",
       "1                      Rodriguez, Jose; Fumo, Nelson          Article   \n",
       "2  Ma, Chuan; Guerra-Santin, Olivia; Mohammadi, Masi          Article   \n",
       "3              Kholopo, Mota; Rathebe, Phoka Caiphus          Article   \n",
       "4  Patricia, Ariza-Colpas Paola; Rosberg, Pacheco...          Article   \n",
       "\n",
       "                          SourceTitle  Publication Year  \\\n",
       "0  PHYSICS AND CHEMISTRY OF THE EARTH            2024.0   \n",
       "1                      ENERGY REPORTS            2024.0   \n",
       "2            BUILDING AND ENVIRONMENT            2024.0   \n",
       "3                             SENSORS            2024.0   \n",
       "4                             HELIYON            2024.0   \n",
       "\n",
       "                                            Keywords   UT  \\\n",
       "0  Air pollution, Artificial intelligence, Enviro...  WOS   \n",
       "1  Thermal zoning, Demand control ventilation, Es...  WOS   \n",
       "2  Nursing home, Indoor environment, Spatial layo...  WOS   \n",
       "3  radon, environmental exposure, occupational se...  WOS   \n",
       "4  Human activity recognition, Activities of dail...  WOS   \n",
       "\n",
       "                              DOI       ISSN source Abstract  PMID  URL  \n",
       "0       10.1016/j.pce.2024.103604  1474-7065    WOK      NaN   NaN  NaN  \n",
       "1      10.1016/j.egyr.2024.04.025  2352-4847    WOK      NaN   NaN  NaN  \n",
       "2  10.1016/j.buildenv.2024.111452  0360-1323    WOK      NaN   NaN  NaN  \n",
       "3               10.3390/s24102966        NaN    WOK      NaN   NaN  NaN  \n",
       "4   10.1016/j.heliyon.2024.e29398        NaN    WOK      NaN   NaN  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)   \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Article', 'Proceedings Paper', 'Review', 'Journal Article', nan,\n",
       "       'Editorial Material', 'Meeting Abstract', 'Letter', 'Case Reports',\n",
       "       'Patent', 'research-article', 'Journal Article, Review',\n",
       "       \"Journal Article, Research Support, Non-U.S. Gov't\",\n",
       "       'Journal Article, Multicenter Study, Observational Study',\n",
       "       'Journal Article, Review, Systematic Review',\n",
       "       'Journal Article, Randomized Controlled Trial',\n",
       "       'Clinical Trial Protocol, Journal Article',\n",
       "       'Case Reports, Journal Article',\n",
       "       \"Journal Article, Research Support, N.I.H., Extramural, Research Support, Non-U.S. Gov't, Research Support, U.S. Gov't, Non-P.H.S., Research Support, U.S. Gov't, P.H.S.\",\n",
       "       \"Journal Article, Randomized Controlled Trial, Research Support, Non-U.S. Gov't\",\n",
       "       \"Journal Article, Research Support, N.I.H., Extramural, Research Support, U.S. Gov't, Non-P.H.S.\",\n",
       "       \"Journal Article, Observational Study, Research Support, N.I.H., Extramural, Research Support, Non-U.S. Gov't\",\n",
       "       \"Journal Article, Research Support, Non-U.S. Gov't, Review\",\n",
       "       \"Case Reports, Research Support, Non-U.S. Gov't\",\n",
       "       'Journal Article, Research Support, N.I.H., Extramural',\n",
       "       \"Research Support, Non-U.S. Gov't, Systematic Review\",\n",
       "       'Systematic Review',\n",
       "       \"Journal Article, Research Support, U.S. Gov't, P.H.S.\",\n",
       "       'Journal Article, Observational Study',\n",
       "       \"Journal Article, Research Support, N.I.H., Extramural, Research Support, Non-U.S. Gov't\",\n",
       "       \"Journal Article, Research Support, U.S. Gov't, Non-P.H.S.\",\n",
       "       \"Journal Article, Research Support, Non-U.S. Gov't, Research Support, U.S. Gov't, Non-P.H.S.\",\n",
       "       \"Journal Article, Research Support, Non-U.S. Gov't, Review, Systematic Review\",\n",
       "       'article', 'proceedings', 'inproceedings', 'book', 'inbook'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in Publication Type, get unique values\n",
    "data['Publication Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename publication types to consolidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'article', 'Article' and 'Journal Article' are the same\n",
    "data['Publication Type'] = data['Publication Type'].replace('Journal Article', 'Article')\n",
    "data['Publication Type'] = data['Publication Type'].replace('article', 'Article')\n",
    "data['Publication Type'] = data['Publication Type'].replace('research-article', 'Article')\n",
    "\n",
    "# proceedings, inproceedings, Proceedings Paper are the same\n",
    "data['Publication Type'] = data['Publication Type'].replace('Proceedings Paper', 'Proceedings')\n",
    "data['Publication Type'] = data['Publication Type'].replace('inproceedings', 'Proceedings')\n",
    "data['Publication Type'] = data['Publication Type'].replace('proceedings', 'Proceedings')\n",
    "\n",
    "# book and inbook are the same\n",
    "data['Publication Type'] = data['Publication Type'].replace('inbook', 'Book')\n",
    "data['Publication Type'] = data['Publication Type'].replace('book', 'Book')\n",
    "\n",
    "data['Publication Type Other'] = data['Publication Type'].apply(lambda x: ','.join(x.split(',')[1:]) if isinstance(x, str) else '')\n",
    "data['Publication Type'] = data['Publication Type'].apply(lambda x: x.split(',')[0] if isinstance(x, str) else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries where the Publication Type is blank are found in Web of Science - DIIDW database, which is the Derwent Innovations Index -- patents. Also remove types that are obviously not a study/paper -- Clinical Trial Protocol, Research Support (a review paper), Patent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Article' 'Proceedings' 'Review' 'Editorial Material' 'Meeting Abstract'\n",
      " 'Letter' 'Case Reports' 'Journal Article' 'Systematic Review' 'Book']\n",
      "(5028, 14)\n"
     ]
    }
   ],
   "source": [
    "# remove rows that have the UT = DIIDW\n",
    "data = data[data['UT'] != 'DIIDW']\n",
    "# remove rows with Clinical Trial Protocol, Research Support, Patent in Publication Type\n",
    "data = data[~data['Publication Type'].isin(['Clinical Trial Protocol', 'Research Support', 'Patent'])]\n",
    "print(data['Publication Type'].unique())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EC1: Works that are survey/review papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4938, 14)\n"
     ]
    }
   ],
   "source": [
    "# remove rows that are Review, Systematic Review\n",
    "data = data[~data['Publication Type'].isin(['Review', 'Systematic Review'])]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_review\n",
      "False    4879\n",
      "True       59\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# search the string in Title whther it contains 'review' but not 'reviews'\n",
    "data['is_review'] = data['Title'].apply(lambda x: 'review' in x.lower() and 'reviews' not in x.lower())\n",
    "print(data['is_review'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checked through those marked True and they were all literature papers so they can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4879, 14)\n"
     ]
    }
   ],
   "source": [
    "# drop rows that are reviews\n",
    "data = data[~data['is_review']]\n",
    "# drop the is_review column\n",
    "data = data.drop(columns=['is_review'])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EC5: Works relating specifically to COVID since these works might not be representative of the normal (non-COVID) situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_covid\n",
      "False    4718\n",
      "True      161\n",
      "Name: count, dtype: int64\n",
      "(4718, 14)\n"
     ]
    }
   ],
   "source": [
    "# search through title for the word covid or coronavirus\n",
    "data['is_covid'] = data['Title'].apply(lambda x: 'covid' in x.lower() or 'coronavirus' in x.lower())\n",
    "print(data['is_covid'].value_counts())\n",
    "# drop rows that are covid related\n",
    "data = data[~data['is_covid']]\n",
    "# drop the is_covid column\n",
    "data = data.drop(columns=['is_covid'])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "is_duplicate\n",
      "False    4684\n",
      "True       34\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# are there duplicate titles?\n",
    "print(data['Title'].duplicated().sum())\n",
    "# mark duplicates and the original\n",
    "data['is_duplicate'] = data['Title'].duplicated(keep=False)\n",
    "print(data['is_duplicate'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_duplicate\n",
      "False    4701\n",
      "Name: count, dtype: int64\n",
      "(4701, 14)\n"
     ]
    }
   ],
   "source": [
    "# if the duplicate is from the same source, keep the first one\n",
    "data = data[~(data['is_duplicate'] & data.duplicated(subset=['Title', 'source']))]\n",
    "# if the duplicate is from different sources, keep the one that is not from WOK\n",
    "data = data[~(data['is_duplicate'] & (data['source'] == 'WOK'))]\n",
    "data['is_duplicate'] = data['Title'].duplicated(keep=False)\n",
    "print(data['is_duplicate'].value_counts())\n",
    "# if there are no more duplicates, drop the is_duplicate column\n",
    "if not data['is_duplicate'].any():\n",
    "    data = data.drop(columns=['is_duplicate'])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "acm       3567\n",
      "WOK        827\n",
      "pubmed     307\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print the number of rows for each source\n",
    "print(data['source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('literature/wb2_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
